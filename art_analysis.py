#Arjun Rajpal#IDS Final Capstone#Importsimport pandas as pdimport matplotlib as mplimport matplotlib.pyplot as pltimport numpy as npfrom scipy.stats import kstestfrom scipy import stats as scpfrom scipy.stats import binned_statisticfrom sklearn.model_selection import train_test_splitfrom sklearn.linear_model import LinearRegressionfrom sklearn.linear_model import LogisticRegressionfrom sklearn.metrics import roc_auc_scorefrom sklearn.linear_model import Ridgefrom sklearn.linear_model import RidgeCVfrom sklearn.metrics import r2_scorefrom sklearn.metrics import mean_squared_errorfrom sklearn.cluster import KMeansfrom sklearn.metrics import silhouette_scorefrom sklearn.decomposition import PCA#Seeding random number generator#I will use the variable seed when needed throughout the project to seed random number selectionnp.random.seed(14112597)seed = 14112597#Bringing in Dataart = pd.read_csv('theArt.csv')data = pd.read_csv('theData.csv', header = None)#note all tests assume alpha level 0.05#Question 1#-----------------------------#Is classical art more well liked than modern art?# Null Hypothesis: classical art is equally liked as modern art#Alternative Hypothesis: classical art more well liked than modern artprint("Quesion 1 Info Below: ")#idea - find the mode rating for classical works by each reviewer# - run KS test and ManWitU test#divide art up based on style and fetch the indexes of columns that are classical#and modern#Then fetch dataclassical_art = art[art.iloc[:, 5] == 1].iloc[:,0]modern_art = art[art.iloc[:, 5] == 2].iloc[:,0]classical_art_id_array = classical_art.to_numpy().T - 1modern_art_id_array = modern_art.to_numpy().T - 1classical_ratings = data.iloc[:,classical_art_id_array]modern_ratings = data.iloc[:,modern_art_id_array]#Combine data for cleaning#dropping na values row wisecombined_classical_modern = np.append(classical_ratings, modern_ratings, 1)combined_classical_modern = combined_classical_modern[~np.isnan(combined_classical_modern).any(axis=1)]classical_ratings = combined_classical_modern[:,0:35]modern_ratings = combined_classical_modern[:,35:]print(classical_ratings.shape)#finding the most common rating amongst reviewers for classical and modern artclassical_ratings_medians = np.median(classical_ratings,axis = 1)modern_ratings_medians = np.median(modern_ratings,axis = 1)#plotting two distributions of modeplt.hist(classical_ratings_medians,alpha=0.5,label="Classical Art")plt.hist(modern_ratings_medians,alpha=0.5,label="Modern Art")plt.axvline(np.median(classical_ratings_medians), color='r', linestyle='dashed', linewidth=1, label="Median Classical")plt.axvline(np.median(modern_ratings_medians), color='k', linestyle='dashed', linewidth=1, label="Median Modern")plt.title("Median Art Ratings For Each Reviewer")plt.xlabel("Median Rating (1 - 7)")plt.legend()plt.show()#Man Whittney Ustatistic, p_value = scp.mannwhitneyu(classical_ratings_medians, modern_ratings_medians, alternative='two-sided')print()print("MW results")print("P-Value: " + str(p_value))if p_value < 0.05:    print("The distributions are significantly different at alpha 0.05.")else:    print("The distributions are not significantly different at alpha 0.05.")print()    statistic, p_value = kstest(classical_ratings_medians.flatten(), modern_ratings_medians.flatten())print()print("KS Test Results")print("P-Value: " + str(p_value))if p_value < 0.05:    print("The distributions are significantly different at alpha 0.05.")else:    print("The distributions are not significantly different at alpha 0.05.")print()print()#We reject the null#paired t testt_statistic, p_value = scp.ttest_rel(classical_ratings_medians, modern_ratings_medians)print("Paired t-test results:")print("T-statistic:", t_statistic)print("P-value:", p_value)if p_value < 0.05:    print("The distributions are significantly different at alpha 0.05.")else:    print("The distributions are not significantly different at alpha 0.05.")print()#Question 2#-----------------------------#Is there a difference in the preference ratings for modern art vs. non-human (animals and computers) generated art?# Null Hypothesis: non-human and modern art are independent#Alternative Hypothesis: non-human is not equally liked as modern artprint("Question 2 Results:")#Fetchingnonhuman_art = art[art.iloc[:, 5] == 3].iloc[:,0]nonhuman_id_array = nonhuman_art.to_numpy().T - 1nonhuman_ratings = data.iloc[:,nonhuman_id_array]modern_ratings = data.iloc[:,modern_art_id_array]combined_modern_nonhuman = np.append(modern_ratings,nonhuman_ratings, 1)combined_modern_nonhuman  = combined_modern_nonhuman[~np.isnan(combined_modern_nonhuman).any(axis=1)]modern_ratings = combined_modern_nonhuman[:,0:35]nonhuman_ratings = combined_modern_nonhuman[:,35:]modern_ratings_medians = np.median(modern_ratings,axis = 1)nonhuman_ratings_medians = np.median(nonhuman_ratings,axis = 1)#plotting two distributions of modeplt.hist(nonhuman_ratings_medians,alpha=0.8,label="Non-Human Art")plt.hist(modern_ratings_medians,alpha=0.5,label="Modern Art")plt.axvline(np.median(nonhuman_ratings_medians), color='k', linestyle='dashed', linewidth=1, label="Median Non-Human")plt.axvline(np.median(modern_ratings_medians), color='k', linestyle='dashed', linewidth=1, label="Median Modern")plt.title("Median Art Ratings For Each Reviewer")plt.xlabel("Median Rating (1 - 7)")plt.legend()plt.show()#Man Whittney Ustatistic, p_value = scp.mannwhitneyu(nonhuman_ratings_medians, modern_ratings_medians, alternative='two-sided')print("MW results: ")print("P-Value: " + str(p_value))if p_value < 0.05:    print("The distributions are significantly different at alpha 0.05.")else:    print("The distributions are not significantly different at alpha 0.05.")print()#KS Teststatistic, p_value = kstest(nonhuman_ratings_medians.flatten(), modern_ratings_medians.flatten())print("KS Test Results")print("P-Value: " + str(p_value))if p_value < 0.05:    print("The distributions are significantly different at alpha 0.05.")else:    print("The distributions are not significantly different at alpha 0.05.")print()t_statistic, p_value = scp.ttest_rel(nonhuman_ratings_medians, modern_ratings_medians)print("Paired t-test results:")print("T-statistic:", t_statistic)print("P-value:", p_value)if p_value < 0.05:    print("The distributions are significantly different at alpha 0.05.")else:    print("The distributions are not significantly different at alpha 0.05.")print()print()#Question 3#-----------------------------#Do women give higher art preference ratings than men?# Null Hypothesis: men and women give similar art ratings#Alternative Hypothesis: women give higher preference#note rows are independent#extracting ratings for men and womenprint("Question 3 Results:")men_data = data[data[216] == 1]women_data = data[data[216] == 2]men_ratings = men_data.iloc[:,0:91].dropna(axis=0)women_ratings = women_data.iloc[:,0:91].dropna(axis=0)print("Number of Men in Study (after dropping NAs): " + str(men_ratings.shape[0]))print("Number of Women in Study (after dropping NAs): " + str(women_ratings.shape[0]))men_medians = np.median(men_ratings,axis=1)women_medians = np.median(women_ratings,axis=1)#plotting two distributions of modeplt.hist(women_medians,alpha=0.8,label="Women Scores")plt.hist(men_medians,alpha=0.5,label="Men Scores")plt.axvline(np.median(women_medians), color='r', linestyle='dashed', linewidth=1, label="Median Women")plt.axvline(np.median(men_medians), color='k', linestyle='dashed', linewidth=1, label="Median Men")plt.title("Median Art Ratings For Each Reviewer")plt.xlabel("Median Rating (1 - 7)")plt.legend()plt.show()print("MW results: ")genderMUu, genderMUp = scp.mannwhitneyu(women_medians, men_medians)if genderMUp < 0.05:    print("The distributions of the medians are significantly different according to the Mann-Whitney U test (p-value = {:.3f})".format(genderMUp))else:    print("The distributions of the medians are not significantly different according to the Mann-Whitney U test (p-value = {:.3f})".format(genderMUp))print()#cannot do paired t test because un-equal n#Question 4#-----------------------------#Is there a difference in the preference ratings of users with some art background (some art education) vs. none?#chi-squaredprint("Question 4 information")#extracting ratings for people with and without art backgroundwithout_art_exp_data = data[data[218] == 0]with_art_exp_data = data[data[218] != 0]without_art_ratings = without_art_exp_data.iloc[:,0:91]with_art_ratings = with_art_exp_data.iloc[:,0:91]without_art_ratings['median'] = without_art_ratings.median(axis=1, skipna=True)with_art_ratings['median'] = with_art_ratings.median(axis=1, skipna=True)without_art_medians = without_art_ratings['median'].to_numpy()with_art_medians = with_art_ratings['median'].to_numpy()#plot dataplt.hist(with_art_medians,alpha=0.5,label="With Art Exp")plt.hist(without_art_medians,alpha=0.8,label="Without Art Exp")plt.axvline(np.median(without_art_medians), color='r', linestyle='solid', linewidth=1, label="Without Median")plt.axvline(np.median(with_art_medians), color='k', linestyle='dashed', linewidth=1, label="With Median")plt.title("Median Art Ratings For Each Reviewer")plt.xlabel("Median Rating (1 - 7)")plt.legend()plt.show()artu, artMWUp = scp.mannwhitneyu(without_art_medians, with_art_medians)if artMWUp < 0.05:    print("The distributions of the medians are significantly different according to the Mann-Whitney U test (p-value = {:.3f})".format(artMWUp))else:    print("The distributions of the medians are not significantly different according to the Mann-Whitney U test (p-value = {:.3f})".format(artMWUp))print()#cannot do paired t test because un-equal n#Question 5#-----------------------------# Build a regression model to predict art preference ratings from energy ratings only. Make sure#to use cross-validation methods to avoid overfitting and characterize how well your model#predicts art preference ratings.print("Question 5 information")#Gathering preference ratings and energy ratings for all 91 pieces of artpref_energy = data.iloc[:,0:182]#Row wise removal of na valuespref_energy_clean = pref_energy.dropna()#Unit of analysis = each individual reviewer# we cannot just use artworks as the unit of analysis because they are not independent as the same people read themdataNAN = data.iloc[:,0:182].dropna(axis=0)#Seprating scores out by each grouppreference_means = np.mean(dataNAN.iloc[:,0:91].to_numpy(), axis=0)energy_means = np.mean(dataNAN.iloc[:,91:182].to_numpy(),axis=0)#Generating Plots of Dataplt.scatter(energy_means, preference_means )plt.title("Mean Energy Vs. Mean Preference Score for Reviewers")plt.xlabel("Mean Energy Score")plt.ylabel("Mean Preference Score")plt.show()#Linear regression doesn't make any sense when working with this data - it would provide meaningless eval#We will now find a way to split this data to classify it into to outcome categoriesplt.hist(preference_means, bins = np.arange(8)-0.5)plt.axvline(np.nanmean(preference_means), color = 'k',linestyle='dashed', linewidth=1, label = 'mean')plt.axvline(np.nanmedian(preference_means), color = 'r',linestyle='dashed', linewidth=1, label = 'median')plt.title("Mean Preference Scores for each Reviewer")plt.xlabel("Mean Preference ScoreScore")plt.ylabel("Count")plt.legend()plt.show()xtrain, xtest, ytrain, ytest = train_test_split(energy_means, preference_means, test_size = 0.2,random_state = seed)#Cross validatelinearModel = LinearRegression()energyModel = linearModel.fit(xtrain.reshape(-1, 1),ytrain)plt.scatter(xtest, ytest)plt.plot(xtest, energyModel.predict(xtest.reshape(-1, 1)), label='Energy Regression Model')plt.title("Mean Preference Scores for each Reviewer")plt.xlabel("Mean Preference ScoreScore")plt.ylabel("Count")plt.legend()plt.show()rmse = mean_squared_error(ytest, energyModel.predict(xtest.reshape(-1, 1)), squared=True)rsqrd2 = energyModel.score(xtest.reshape(-1, 1), energyModel.predict(xtest.reshape(-1, 1)))predictions = energyModel.predict(xtest.reshape(-1, 1))# Calculate R2r2 = r2_score(ytest, predictions)# Calculate RMSEmse = mean_squared_error(ytest, predictions)rmse = np.sqrt(mse)print("R2:", r2)print("RMSE:", rmse)#Question 6#-----------------------------# Build a regression model to predict art preference ratings from energy ratings and# demographic information. Make sure to use cross-validation methods to avoid overfitting and# comment on how well your model predicts relative to the “energy ratings only” model.print("Question 6 information")#Question 7#-----------------------------#Considering the 2D space of average preference ratings vs. average energy rating (that#contains the 91 art pieces as elements), how many clusters can you – algorithmically - identify in this space? #Make sure to comment on the identity of the clusters – do they correspond to particular types of art?print("")print("Question 7 Results:")#dropping rows that are not dataNAN = data.iloc[:,0:182].dropna(axis=0)print(dataNAN.shape)preference_medians = np.mean(dataNAN.iloc[:,0:91].to_numpy(), axis=0)energy_medians = np.mean(dataNAN.iloc[:,91:182].to_numpy(),axis=0)preference_energy = np.append(energy_medians.reshape(-1, 1), preference_medians.reshape(-1, 1), 1)silhouette = []#finding right k value for our clusterfor i in range(2, 15):    clusterModel = KMeans(n_clusters=i)    clust = clusterModel.fit_predict(preference_energy)    silhouette.append(silhouette_score(preference_energy, clust))    silhouette = np.array(silhouette)print(silhouette)plt.bar(range(2,15),silhouette)plt.title("Silhouette Score by K Value for KMeans Cluster")plt.xlabel("K value")plt.ylabel("Score")plt.show()clusterModel = KMeans(n_clusters=2)clust = clusterModel.fit_predict(preference_energy)plt.scatter(preference_energy[:, 0], preference_energy[:, 1], c=clust, s=50, cmap='tab10',label="colored by kmeans with k = 4")plt.suptitle("Average Energy Score Vs. Average Preference Score")plt.title("Kmeans Clustering (k=2)")plt.xlabel("Average Energy Score")plt.ylabel("Average Preference Score")plt.show()clusterModel = KMeans(n_clusters=3)clust = clusterModel.fit_predict(preference_energy)plt.scatter(preference_energy[:, 0], preference_energy[:, 1], c=clust, s=50, cmap='tab10',label="colored by kmeans with k = 4")plt.suptitle("Average Energy Score Vs. Average Preference Score")plt.title("Kmeans Clustering (k=3)")plt.xlabel("Average Energy Score")plt.ylabel("Average Preference Score")plt.show()clusterModel = KMeans(n_clusters=4)clust = clusterModel.fit_predict(preference_energy)plt.scatter(preference_energy[:, 0], preference_energy[:, 1], c=clust, s=50, cmap='tab10',label="colored by kmeans with k = 4")plt.suptitle("Average Energy Score Vs. Average Preference Score")plt.title("Kmeans Clustering (k=4)")plt.xlabel("Average Energy Score")plt.ylabel("Average Preference Score")plt.show()art_type_code = art.iloc[:,5]plt.scatter(preference_energy[:, 0], preference_energy[:, 1], c=art_type_code, s=50, cmap='tab10',label="colored by type code")plt.suptitle("Average Energy Score Vs. Average Preference Score")plt.title("Art Type Grouping (3 Types)")plt.xlabel("Average Energy Score")plt.ylabel("Average Preference Score")plt.show()#to do generate plot of values that are based off categories#Question 8#-----------------------------#Considering only the first principal component of the self-image ratings as inputs to a regression model #– how well can you predict art preference ratings from that factor alone?print()print("Question 8 Answers: ")#extracting needed dataself_image_data = data.to_numpy()[:,205:215]preference = np.reshape(np.nanmean(data.to_numpy()[:,0:91],axis=1), (300,1))all_data = np.append(preference, self_image_data,axis=1)plt.hist(preference)plt.title('Mean Preferences Distribuiton')plt.xlabel("Mean Preference Score")plt.show()#dropping na values row wiseall_data = all_data[~np.isnan(all_data).any(axis=1)]self_image_data = all_data[:,1:]zscored_self_image_data  = scp.zscore(self_image_data)plt.imshow(np.corrcoef(self_image_data,rowvar=False))plt.title("Correlation Matrix For Self Image Data")plt.xlabel("Column Index")plt.ylabel("Column Index")plt.colorbar()plt.show()self_Image_PCA = PCA().fit(zscored_self_image_data)eigVals = self_Image_PCA.explained_variance_loadings = self_Image_PCA.components_*-1origDataNewCoordinates = self_Image_PCA.fit_transform(zscored_self_image_data)*-1numPredictors = 10plt.bar(np.linspace(1,numPredictors,numPredictors),eigVals)plt.title('Scree plot for Self Image Ratings PCA')plt.xlabel('Principal Components')plt.ylabel('Eigenvalues')plt.show()#extracting first principle component# First Principle Component - determining Meaningplt.bar(np.linspace(1,numPredictors,numPredictors),loadings[0,:]) plt.title('Overall Self Image')plt.xlabel('Features')plt.show()#for the first factor we are using all the variables 1-10y = scp.zscore(all_data[:,0])xtrain, xtest, ytrain, ytest = train_test_split(self_image_data, y, test_size = 0.20,random_state = seed)linModel = RidgeCV(alphas=(0.01, 10.0,0.1))selfImage_fpc = linModel.fit(xtrain, ytrain)predictions = linModel.predict(xtest)# Calculate R2r2 = r2_score(ytest, predictions)# Calculate RMSEmse = mean_squared_error(ytest, predictions)rmse = np.sqrt(mse)print("Linear Regression Model Results for First PC: ")print("R2:", r2)print("RMSE:", rmse)#We cannot predict art ratings well with self image data alone#Question 9#-----------------------------#Consider the first 3 principal components of the “dark personality” traits – use these as inputs to a regression model to predict art preference ratings. #Which of these components significantly predict art preference ratings? #Comment on the likely identity of these factors (e.g. narcissism, manipulativeness, callousness, etc.).print()print()print("Question 9 Answers Below")#extracting needed datadark_pers_data = data.to_numpy()[:,182:194]preference = np.reshape(np.nanmean(data.iloc[:,0:91],axis=1), (300,1))all_data = np.append(preference, dark_pers_data,axis=1)#dropping na values row wiseall_data = all_data[~np.isnan(all_data).any(axis=1)]#extracting dark personality datadark_pers_data = all_data[:,1:]zscored_dark_pers_data  = scp.zscore(dark_pers_data)plt.imshow(np.corrcoef(zscored_dark_pers_data,rowvar=False))plt.title("Correlation Matrix For Dark Personality Traits Data")plt.xlabel("Column Index")plt.ylabel("Column Index")plt.colorbar()plt.show()#PCAdark_pers_data_PCA = PCA().fit(zscored_dark_pers_data)eigVals = dark_pers_data_PCA.explained_variance_loadings = dark_pers_data_PCA.components_*-1origDataNewCoordinates = dark_pers_data_PCA.fit_transform(zscored_dark_pers_data)*-1numPredictors = 12plt.bar(np.linspace(1,numPredictors,numPredictors),eigVals)plt.title('Scree plot for Dark Personality Traits PCA')plt.xlabel('Principal Components')plt.ylabel('Eigenvalues')plt.show()#Features Extracted - all of them 1-12 inclusiveplt.bar(np.linspace(1,numPredictors,numPredictors),loadings[0,:]) plt.title('Has No Dark Personality')plt.xlabel('Features')plt.show()#Features Extracted - 5, 9, 10plt.bar(np.linspace(1,numPredictors,numPredictors),loadings[1,:]) plt.title('Seeks External Validation')plt.xlabel('Features')plt.show()#Features Extracted - 7, 8plt.bar(np.linspace(1,numPredictors,numPredictors),loadings[2,:]) plt.title('Unforgiving/Mean')plt.xlabel('Features')plt.show()#splitting dataxtrain, xtest, ytrain, ytest = train_test_split(zscored_dark_pers_data, all_data[:,0], test_size = 0.2, random_state = seed)#ridge Regression on principle compoent 1rdg=RidgeCV(alphas=(0.01, 10.0,0.1))dark_PC1 = rdg.fit(xtrain, ytrain)prediction = dark_PC1.predict(xtest)adR2 = r2_score(ytest, prediction)rmse = mean_squared_error(ytest, prediction, squared=False)print()print("Print Values for Ridge Regression on Principle Feature 1")print("R-squared Value (test): " + str(adR2))print("RMSE: " + str(rmse)) print("Coef for first three components of : " + str(dark_PC1.coef_))#print("Ideal Alpha Value: " + str(dark_threePCs.alpha_))#ridge Regression on principle compoent 2rdg=RidgeCV(alphas=(0.01, 10.0,0.1))dark_PC2 = rdg.fit(xtrain[:,[4,5,8,9]], ytrain)prediction = dark_PC2.predict(xtest[:,[4,5,8,9]])adR2 = r2_score(ytest, prediction)rmse = mean_squared_error(ytest, prediction, squared=False)print()print("Print Values for Ridge Regression on Principle Feature 2")print("Adjusted R-squared Value (test): " + str(adR2))print("RMSE: " + str(rmse)) print("Coef for first three components of : " + str(dark_PC2.coef_))#print("Ideal Alpha Value: " + str(dark_threePCs.alpha_))#ridge Regression on principle compoent 2rdg=RidgeCV(alphas=(0.01, 10.0,0.1))dark_PC3 = rdg.fit(xtrain[:,[6,7]], ytrain)prediction = dark_PC3.predict(xtest[:,[6,7]])adR2 = r2_score(ytest, prediction)rmse = mean_squared_error(ytest, prediction, squared=False)print()print("Print Values for Ridge Regression on Principle Feature 3")print("Adjusted R-squared Value (test): " + str(adR2))print("RMSE: " + str(rmse)) print("Coef for first three components of : " + str(dark_PC3.coef_))#print("Ideal Alpha Value: " + str(dark_threePCs.alpha_))# Answer#Tells us that the second principle component best predicts the average better than all the other compoents#Would be Compoent 2: Seeking External Validation as adjusted Rsquared is higher than what was achived with other models#note that it is still very low over all 0.06997782132414387.#none of them really do a paticularly great job of predicting though#More data is needed.#Component 1: How Dark a person is?#Component 2: Does seek external validation (needy)#Component 3: Unforgiving/Mean#Question 10#-----------------------------#Can you determine the political orientation of the users (to simplify things and avoid gross class imbalance issues, #you can consider just 2 classes: “left” (progressive & liberal) vs. “non- left” (everyone else)) #from all the other information available, using any classification model of your choice? #Make sure to comment on the classification quality of this model.